{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from models.ddpg import DDPG\n",
    "from models.model import OUNoise\n",
    "from env.TradeEnv import TradeEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize trade environment...\n",
      "Aligning df_macro, df_stock and df_factor...\n",
      "df_macro shape:  (2674, 54)\n",
      "df_stock shape:  (2674, 470)\n",
      "df_factor shape:  (2674, 470)\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/processed/'\n",
    "df_macro = pd.read_csv(file_path + 'macro_data.csv')\n",
    "df_stock = pd.read_csv(file_path + 'stock_data.csv')\n",
    "df_factor = pd.read_csv(file_path + 'factor_data.csv')\n",
    "\n",
    "env = TradeEnv(df_macro=df_macro, df_factor=df_factor, df_stock=df_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4, 1400: -0.0003080\n",
      "4, 1500: -0.0003111\n",
      "4, 1600: -0.0003146\n",
      "4, 1700: -0.0003080\n",
      "4, 1800: -0.0003083\n",
      "4, 1900: -0.0003193\n",
      "4, 2000: -0.0003233\n",
      "4, 2100: -0.0003324\n",
      "4, 2200: -0.0003393\n",
      "4, 2300: -0.0003437\n",
      "4, 2400: -0.0003564\n",
      "4, 2500: -0.0003611\n",
      "4, 2600: -0.0003653\n",
      "5,    0: -0.0010000\n",
      "5,  100: -0.0005678\n",
      "5,  200: -0.0006067\n",
      "5,  300: -0.0005832\n",
      "5,  400: -0.0005889\n",
      "5,  500: -0.0005935\n",
      "5,  600: -0.0005534\n",
      "5,  700: -0.0005477\n",
      "5,  800: -0.0005510\n",
      "5,  900: -0.0005393\n",
      "5, 1000: -0.0005406\n",
      "5, 1100: -0.0005452\n",
      "5, 1200: -0.0005225\n",
      "5, 1300: -0.0005007\n",
      "5, 1400: -0.0004965\n",
      "5, 1500: -0.0004943\n",
      "5, 1600: -0.0004966\n",
      "5, 1700: -0.0004930\n",
      "5, 1800: -0.0004919\n",
      "5, 1900: -0.0004866\n",
      "5, 2000: -0.0004764\n",
      "5, 2100: -0.0004687\n",
      "5, 2200: -0.0004666\n",
      "5, 2300: -0.0004565\n",
      "5, 2400: -0.0004530\n",
      "5, 2500: -0.0004453\n",
      "5, 2600: -0.0004355\n",
      "6,    0: -0.0010000\n",
      "6,  100: -0.0002880\n",
      "6,  200: -0.0003144\n",
      "6,  300: -0.0002725\n",
      "6,  400: -0.0002455\n",
      "6,  500: -0.0002495\n",
      "6,  600: -0.0002417\n",
      "6,  700: -0.0002414\n",
      "6,  800: -0.0002418\n",
      "6,  900: -0.0002357\n",
      "6, 1000: -0.0002286\n",
      "6, 1100: -0.0002264\n",
      "6, 1200: -0.0002172\n",
      "6, 1300: -0.0002125\n",
      "6, 1400: -0.0002074\n",
      "6, 1500: -0.0002050\n",
      "6, 1600: -0.0002024\n",
      "6, 1700: -0.0001995\n",
      "6, 1800: -0.0001967\n",
      "6, 1900: -0.0001956\n",
      "6, 2000: -0.0001934\n",
      "6, 2100: -0.0001917\n",
      "6, 2200: -0.0001902\n",
      "6, 2300: -0.0001894\n",
      "6, 2400: -0.0001882\n",
      "6, 2500: -0.0001877\n",
      "6, 2600: -0.0001862\n",
      "7,    0: -0.0010000\n",
      "7,  100: -0.0001489\n",
      "7,  200: -0.0001548\n",
      "7,  300: -0.0001530\n",
      "7,  400: -0.0001483\n",
      "7,  500: -0.0001472\n",
      "7,  600: -0.0001508\n"
     ]
    }
   ],
   "source": [
    "agent = DDPG(env=env)\n",
    "\n",
    "batch_size = 128\n",
    "rewards = []\n",
    "avg_rewards = []\n",
    "\n",
    "for episode in range(50):\n",
    "    state = env.reset()\n",
    "    # noise.reset()\n",
    "    episode_reward = 0\n",
    "    \n",
    "    for i in range(5000):\n",
    "        action = agent.get_action(state)\n",
    "        # action = noise.get_action(action, step)\n",
    "        next_state, reward, terminated = env.step(action) \n",
    "        if not terminated:\n",
    "            agent.memory.push(state, action, reward, next_state, terminated)\n",
    "        \n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "\n",
    "        if len(agent.memory) > 1e4:\n",
    "            agent.update(batch_size) \n",
    "            if (i+1) % 100 == 0:\n",
    "                print('{}, {:>4d}: {:.7f}'.format(episode, i, episode_reward / (i+1)))\n",
    "\n",
    "        if terminated:\n",
    "            # sys.stdout.write(\"episode: {}, reward: {}, average _reward: {} \\n\".format(episode, np.round(episode_reward, decimals=2), np.mean(rewards[-10:])))\n",
    "            break\n",
    "\n",
    "    rewards.append(episode_reward)\n",
    "    avg_rewards.append(np.mean(rewards[-10:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rewards)\n",
    "plt.plot(avg_rewards)\n",
    "plt.plot()\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
